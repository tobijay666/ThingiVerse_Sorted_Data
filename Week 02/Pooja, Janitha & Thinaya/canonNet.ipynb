{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfa9714d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Model ID       Model Type\n",
      "0   41106.stl       FLAT MODEL\n",
      "1  137749.stl  FREE-FORM MODEL\n",
      "2   32770.stl  FREE-FORM MODEL\n",
      "3   34783.stl  FREE-FORM MODEL\n",
      "4   34784.stl  FREE-FORM MODEL\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Prepare Your Data\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# List STL files in your dataset folder\n",
    "dataset_folder = r'D:\\research\\small_big_flat_free\\dataset- check'\n",
    "stl_files = [f for f in os.listdir(dataset_folder) if f.lower().endswith('.stl')]\n",
    "\n",
    "# Read manual labels from CSV\n",
    "labels_df = pd.read_csv(r'D:\\research\\small_big_flat_free\\label.csv')\n",
    "print(labels_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b264a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique label values: ['FLAT MODEL' 'FREE-FORM MODEL' nan]\n"
     ]
    }
   ],
   "source": [
    "# Check unique label values in the updated label CSV\n",
    "print('Unique label values:', labels_df.iloc[:,1].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f461775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert STL Files to Point Clouds\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def stl_to_pointcloud(stl_path, n_points=1024):\n",
    "    mesh = trimesh.load(stl_path)\n",
    "    points, _ = trimesh.sample.sample_surface(mesh, n_points)\n",
    "    return points\n",
    "\n",
    "# Create the pointclouds directory if it doesn't exist\n",
    "os.makedirs('pointclouds', exist_ok=True)\n",
    "\n",
    "for stl_file in stl_files:\n",
    "    stl_path = os.path.join(dataset_folder, stl_file)\n",
    "    points = stl_to_pointcloud(stl_path)\n",
    "    np.save(f\"pointclouds/{os.path.splitext(stl_file)[0]}.npy\", points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31b04373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Preprocess Point Clouds (Canonicalization)\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "\n",
    "def canonicalize_pointcloud(points):\n",
    "    # Center\n",
    "    centered = points - np.mean(points, axis=0)\n",
    "    # PCA alignment\n",
    "    pca = PCA(n_components=3)\n",
    "    aligned = pca.fit_transform(centered)\n",
    "    # Sort by coordinates for consistency\n",
    "    sorted_points = aligned[np.lexsort((aligned[:,2], aligned[:,1], aligned[:,0]))]\n",
    "    return sorted_points\n",
    "\n",
    "import glob\n",
    "os.makedirs('canonical', exist_ok=True)\n",
    "for npy_file in glob.glob('pointclouds/*.npy'):\n",
    "    points = np.load(npy_file)\n",
    "    canonical = canonicalize_pointcloud(points)\n",
    "    np.save(f\"canonical/{os.path.basename(npy_file)}\", canonical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e101774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label CSV columns: Index(['Model ID', 'Model Type'], dtype='object')\n",
      "[('canonical\\\\103742.npy', 'FLAT MODEL'), ('canonical\\\\103815.npy', 'FLAT MODEL'), ('canonical\\\\103817.npy', 'FLAT MODEL'), ('canonical\\\\103821.npy', 'FLAT MODEL'), ('canonical\\\\103824.npy', 'FREE-FORM MODEL')]\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Match Point Clouds with Labels\n",
    "canonical_folder = 'canonical'\n",
    "matched = []\n",
    "print('Label CSV columns:', labels_df.columns)  # Debug: print columns to find correct name\n",
    "# Update 'model' to the actual column name if needed, e.g., 'filename' or similar\n",
    "for npy_file in glob.glob(f'{canonical_folder}/*.npy'):\n",
    "    model_name = os.path.splitext(os.path.basename(npy_file))[0] + '.stl'  # Add .stl to match CSV\n",
    "    # Change 'model' to the correct column name below\n",
    "    label_row = labels_df[labels_df.iloc[:,0] == model_name]  # Use first column for matching\n",
    "    if not label_row.empty:\n",
    "        label = label_row.iloc[0,1]  # Use second column for label\n",
    "        matched.append((npy_file, label))\n",
    "print(matched[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a912b3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution: Counter({'FREE-FORM MODEL': 124, 'FLAT MODEL': 121})\n"
     ]
    }
   ],
   "source": [
    "# Check label distribution in matched dataset\n",
    "from collections import Counter\n",
    "labels = [label for _, label in matched]\n",
    "label_counts = Counter(labels)\n",
    "print('Label distribution:', label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d02eeec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in d:\\softwares\\anaconda\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in d:\\softwares\\anaconda\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\softwares\\anaconda\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\softwares\\anaconda\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\softwares\\anaconda\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in d:\\softwares\\anaconda\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in d:\\softwares\\anaconda\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in d:\\softwares\\anaconda\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\softwares\\anaconda\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\softwares\\anaconda\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Build the CanonNet Model (MLP)\n",
    "!pip install torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CanonNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "# Example: input_dim = 1024*3 if using 1024 points, each with 3 coordinates\n",
    "model = CanonNet(input_dim=1024*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47f8ea5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0000\n",
      "Epoch 2, Loss: 0.0000\n",
      "Epoch 3, Loss: 0.0000\n",
      "Epoch 4, Loss: 0.0000\n",
      "Epoch 5, Loss: 0.0000\n",
      "Epoch 6, Loss: 0.0000\n",
      "Epoch 4, Loss: 0.0000\n",
      "Epoch 5, Loss: 0.0000\n",
      "Epoch 6, Loss: 0.0000\n",
      "Epoch 7, Loss: 0.0000\n",
      "Epoch 8, Loss: 0.0000\n",
      "Epoch 9, Loss: 0.0000\n",
      "Epoch 7, Loss: 0.0000\n",
      "Epoch 8, Loss: 0.0000\n",
      "Epoch 9, Loss: 0.0000\n",
      "Epoch 10, Loss: 0.0000\n",
      "Epoch 10, Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Train the Model\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class PointCloudDataset(Dataset):\n",
    "    def __init__(self, matched):\n",
    "        self.data = matched\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        npy_file, label = self.data[idx]\n",
    "        points = np.load(npy_file).flatten()\n",
    "        label_idx = 0 if label == 'flat' else 1\n",
    "        return torch.tensor(points, dtype=torch.float32), torch.tensor(label_idx)\n",
    "\n",
    "dataset = PointCloudDataset(matched)\n",
    "\n",
    "if len(dataset) == 0:\n",
    "    print('No matched data found. Please check your labels and point cloud files.')\n",
    "else:\n",
    "    train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(10):\n",
    "        for x, y in train_loader:\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c0e28b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[49]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Softwares\\anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Evaluate the Model\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Split matched data for validation (simple split)\n",
    "val_data = matched[:len(matched)//5]\n",
    "val_dataset = PointCloudDataset(val_data)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x, y in val_loader:\n",
    "        out = model(x)\n",
    "        preds = torch.argmax(out, dim=1)\n",
    "        all_preds.extend(preds.numpy())\n",
    "        all_labels.extend(y.numpy())\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(all_labels, all_preds))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e439109c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\research\\small_big_flat_free\\raw_meshes\\52139.stl: free form\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Use the Model for New Data\n",
    "def classify_new_stl(stl_path, model):\n",
    "    points = stl_to_pointcloud(stl_path)\n",
    "    canonical = canonicalize_pointcloud(points)\n",
    "    x = torch.tensor(canonical.flatten(), dtype=torch.float32).unsqueeze(0)\n",
    "    out = model(x)\n",
    "    pred = torch.argmax(out, dim=1).item()\n",
    "    return 'flat' if pred == 0 else 'free form'\n",
    "\n",
    "# Example usage: classify one STL file from raw_meshes folder\n",
    "single_stl = r'D:\\research\\small_big_flat_free\\raw_meshes\\52139.stl'  # Change to your STL filename\n",
    "result = classify_new_stl(single_stl, model)\n",
    "print(f\"{single_stl}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4ffac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
